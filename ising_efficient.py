import numpy as np
import jax.numpy as jnp
import jax
import typing
import sparse_adj_mat

State = jnp.ndarray
"""For each node, a number in {-1, 0, 1} indicating it's belief"""
Field = typing.Callable[[int, tuple[int]], float]
"""A function that takes a timestep 't' and (an optionally empty) tuple of what node we are looking at and generates some float that is the field strength at that node at that time"""


class BeliefNetwork:
    def __init__(
        self,
        sparse_adj: sparse_adj_mat.Sparse_Adjacency_Matrix,
        external_field: Field,
        init_state: State,
        µ: float = 0.5,
        beta: float = 0.5,
    ):
        """
        :param sparse_adj: Can be generated by helper functions. Represents network topology and connection strengths.
        :type sparse_adj: sparse_adj_mat.Sparse_Adjacency_Matrix
        :param external_field: A function that specifies, for each integer timestep and node idx, what the strength of the external field is. See "Field" type docstring for more.
        :type external_field: Field
        :param init_state: The initial belief state of the nodes.
        :type init_state: State | None
        :param μ: The memory coefficient, in [0, 1]
        :type μ: float
        :param beta: The inverse temperature parameter. Should be nonnegative and below 100.
        :type beta: float
        """

        self.external_field: Field = external_field
        self.init_state = init_state
        self.state = self.init_state
        self.prev_state = self.state
        self.graph_adjacency_mat = sparse_adj
        self.all_states = [self.init_state] #added this as it's used later for diameter
        assert 0 <= µ <= 1, (
            "The memory-parameter µ should be in [0, 1] to remain interpretable"
        )
        self.µ = µ
        assert 100 >= beta >= 0, (
            "Beta, the inverse temperature parameter, should be nonnegative and not too big (leads to underflow)"
        )
        self.beta = beta

        self.neighbors, self.weights = (
            self.graph_adjacency_mat.precompute_neighbors_and_weights()
        )

    def run_for_steps(self, steps: int):
        """Let s = steps and let n = number of nodes. This function runs the simulation for s steps and return a (s + 1, n) integer array which holds, for all s+1 timesteps (including time zero) the state for each node."""
        assert steps > 0, "Run for a positive amount of steps"
        return BeliefNetwork._run_for_steps(
            steps,
            self.neighbors,
            self.weights,
            self.init_state,
            self.external_field,
            # *params
            self.µ,
            self.beta,
        )

    @staticmethod
    def _run_for_steps(
        steps: int, neighbors, weights, init_state: State, field: Field, *params
    ):
        def _step(carry: tuple[State, State], xs) -> tuple[tuple[State, State], State]:
            state, prev_state = carry
            t, key = xs

            new_state = BeliefNetwork._step(
                state,
                prev_state,
                neighbors,
                weights,
                field,
                t,
                key,
                *params,
            )
            return (new_state, state), new_state

        (last_state, prev_state), all_states = jax.lax.scan(
            f=_step,
            init=(init_state, init_state),
            xs=(jnp.arange(steps), jax.random.split(jax.random.PRNGKey(0), steps)),
        )

        # Here we are adding the first state manually because it is dropped otherwise.
        return jnp.concat((init_state[None, :], all_states))

    @staticmethod
    def _step(
        state: State,
        prev_state: State,
        neighbors,
        weights,
        field: Field,
        t: int,
        key,
        *params,
    ) -> State:
        (µ, beta) = params
        n = neighbors.shape[0]
        new_state = jnp.zeros_like(state)

        ss = jnp.array([-1, 0, 1])

        def update_i(i: int, key) -> int:
            nbs = neighbors[i]
            wght = weights[i]
            nbs_states = state[nbs]

            ext = field(t, (i,))
            eff_i = wght @ nbs_states + ext + µ * prev_state[i]

            sample_p = jnp.exp(beta * ss * eff_i)
            sample_p /= jnp.sum(sample_p)
            sample = jax.random.choice(a=ss, p=sample_p, key=key)
            return sample

        new_state = jax.vmap(update_i, in_axes=(0, 0))(
            np.arange(n), jax.random.split(key, n)
        )

        return new_state
