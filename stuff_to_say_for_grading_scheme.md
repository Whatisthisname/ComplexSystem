# Problem Formulation (30%)

## Motivation (5%)
**Motivate/contextualize the work - understand why the analysis is of interest**

Disinformation, misinformation and fake news are becoming an increasingly pressing issue, particularly due to today’s nature of information sharing, which is being changed by the proliferation of social media and the advent of quick content generated by Artificial Intelligence. The increased spread of false content leads to the polarisation of political views, which can have a profound impact on democratic processes as well as increase the risk of political instability and reduce social cohesion. 
This project aims to investigate the sudden transition from neutrality or consensus to bimodal polarisation to attempt to draw conclusions about disinformation spread in social networks. This research aims to investigate these mechanisms by firstly replicating the study by Evangelatos et al. titled “Modeling Disinformation Spread in Social Networks: Phase Transitions and Mean-Field Analysis” and secondly by expanding this model through incorporating temporal dynamics. 


## Data (5%)
**Describe the data; any possible limitations, biases, interpretation, errors, etc.**

## Hypothesis (10%)
**Clearly stated hypotheses/question(s) to test; linked to motivation**

## Clarity (10%)
**Clear idea of scientific value; what it does and doesn't achieve; assumptions are clear**

We are modeling the social networks a as an undirected graph. Each node, representing individuals, can have a state in the set $\{-1, 0, 1\}$, where we interpret $-1$ as being unsupportive of and unconvinced by disinformation, $0$ as being undecided, and $1$ as being affected / supporting it.

The edges are weighted. A positive edge-weight between individuals $a$ and $b$ means that the local energy will be minimized if they agree, while a negative edge weight means that they will tend to disagree. The magnitude of the weight is the strength of this preference.


We are assuming this simple model can reveal some social dynamics.

# Implementation (30%)

## Code (10%)
**How much effort has gone in to implementation; code style; documentation; interface**

The core of our simulation is implemented in JAX, a high-performance numerics library which is similar in syntax to numpy. It can be just-in-time compiled by the python interpreter, which gives many orders of magnitude of speedup over the normal numpy implementation and has allowed us to have a tighter feedback loop when looking for interesting behaviour, and to run more repetitions.

## Plan (10%)
**Was the plan ambitious yet achievable?**

## Analysis (10%)
**Have the correct statistical methods been selected? Are they applied correctly?**

# Results (25%)

## Significance (10%)
**Sufficient evidence to support/reject each hypothesis? OR: is it reported insignificant?**

## Experimental Presentation (5%)
**Graphs/Significance tests/repetition/error bars**

We have nice graphs and we run quite a few repetitions.

## Clear Conclusion (10%)
**Good summary of major findings**
We need to think about this and frame it.

# Poster/Presentation

## Quality of Presentation (10%)
**Figures/graphs/videos/demo/etc.**

We have a lot of nice figures that we can include. I don't think a demo is that useful. We could generate a gif of the network as a small video initially, but low priority I'd say.

## Quality of Explanation
**Ideas clearly explained, good response to questions**

## Bonus
**For asking questions or active participation in discussions** 